# Azure Data Factory Project: Automated Data Fetching & Conditional Data Copy Pipelines ğŸš€

## ğŸ“ˆ Project Overview

This project demonstrates automated data ingestion, transformation, and notification pipelines built using **Azure Data Factory (ADF)**. The core focus areas are:

1. ğŸŒ **REST API Data Fetching & Storage**
2. ğŸ›¢ï¸ **Database to Data Lake Conditional Data Copy with Child Pipeline Triggering**

Additional advanced features include:

* â° Scheduled triggers
* ğŸ“Š Parameter passing between pipelines
* ğŸ“© Gmail notifications for operational monitoring
* ğŸ“ Modular and scalable design

---

## âœ… Tasks Breakdown

### ğŸ“Œ **Task 1: Fetch Country Data using REST API and Save as JSON**

* **Objective:** Automatically fetch data for five countries via REST API and store as JSON files in Azure Data Lake Storage (ADLS).
* **Countries Handled:**

  * ğŸ‡®ğŸ‡³ India
  * ğŸ‡ºğŸ‡¸ US
  * ğŸ‡¬ğŸ‡§ UK
  * ğŸ‡¨ğŸ‡³ China
  * ğŸ‡·ğŸ‡º Russia
* **Details:**

  * API Endpoint: `https://restcountries.com/v3.1/name/{country_name}`
  * Loop through country list dynamically.
  * Save each countryâ€™s JSON response as `{country_name}.json` file in ADLS.

### ğŸ“Œ **Task 2: Create Automated Trigger for Task 1**

* **Objective:** Schedule country data fetching pipeline to run twice daily.
* **Trigger Configuration:**

  * â° 12:00 AM IST
  * â° 12:00 PM IST
* **Benefits:**

  * Eliminates manual execution.
  * Maintains up-to-date country data.

### ğŸ“Œ **Task 3: Conditional Copy of Customer Data from Database to ADLS**

* **Objective:** Copy customer data only when record count exceeds 500.
* **Steps:**

  * Query database to fetch record count.
  * Use If Condition to check: count > 500.
  * If True, copy data from SQL Database to ADLS.
  * Upon success, trigger child pipeline.

### ğŸ“Œ **Task 4: Call Child Product Pipeline if Condition is Met**

* **Objective:** Execute Product Data Pipeline when customer record count exceeds 600.
* **Details:**

  * Pass customer count as a pipeline parameter to child pipeline.
  * Child pipeline handles product data copy based on this parameter.

### ğŸ“Œ **Additional Feature : Gmail Notification for Status Update**

* **Objective:** Notify via Gmail upon success or failure of pipelines.
* **Implementation:**

  * Gmail API / Logic Apps used for notifications.
  * Helps in proactive pipeline monitoring.

---

## ğŸ“‚ Project Folder Structure

```
â”œâ”€â”€ Task 1: CountryData_Fetch_Pipeline ğŸŒ
â”œâ”€â”€ Task 2: Triggers â°
â”œâ”€â”€ Task 3: Customer_Data_Conditional_Copy_Pipeline ğŸ›¢ï¸
â”œâ”€â”€ Task 4: Product_Data_Child_Pipeline ğŸ“¦
â”œâ”€â”€ Task 5: Gmail_Notification_Pipeline ğŸ“©
â”œâ”€â”€ linked_services/
â””â”€â”€ datasets/
```

---

## ğŸ’¡ Key Features ğŸŒŸ

* ğŸŒ REST API Data Ingestion
* ğŸ“Š Parameterized Pipeline Execution
* âœ… Condition-Based Data Copy
* ğŸ—‚ï¸ Dynamic File Naming
* â° Scheduled Trigger Automation
* ğŸ“© Email Notifications
* ğŸ“¦ Modular & Scalable Pipeline Design
* âš™ï¸ Robust Monitoring & Error Handling
* ğŸ“¬ Real-time Gmail-based Status Alerts

---

## ğŸ“– How to Deploy ğŸ› ï¸

1. ğŸ” Import all pipelines, linked services, and datasets into Azure Data Factory instance.
2. ğŸ”§ Configure REST API endpoints, database connections, and ADLS paths.
3. â° Set triggers for automated scheduling.
4. ğŸ“© Deploy notification logic via Gmail API or Logic Apps.
5. ğŸ“Š Monitor pipeline runs via ADF Monitoring panel.

---

## ğŸ“§ Author ğŸ“‡

**Umme Aiman Lalkot**
*Azure Data Engineer Intern | SQL | Azure | ADF | Python*
ğŸ“¬ [ummeaiman1506@gmail.com](mailto:ummeaiman1506@gmail.com)

---
Happy Data Automation! ğŸš€ğŸ‰
